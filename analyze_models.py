#!/usr/bin/env python3
"""
Model Learning Analysis Script
Analyzes the current state of trained models and their learning progress
"""

import os
import pickle
import torch
import pandas as pd
import numpy as np
from datetime import datetime
import joblib

def analyze_model_files():
    """Analyze all model files in the models directory"""
    models_dir = "c:\\Users\\hp\\Binancebot\\models"
    
    if not os.path.exists(models_dir):
        print("‚ùå Models directory not found")
        return
    
    model_files = [f for f in os.listdir(models_dir) if f.endswith(('.pkl', '.pth'))]
    
    if not model_files:
        print("‚ùå No model files found")
        return
    
    # Group by symbol and model type
    model_summary = {}
    
    for file in model_files:
        parts = file.split('_')
        if len(parts) >= 3:
            symbol = parts[0]
            model_type = parts[1]
            timestamp = '_'.join(parts[2:]).replace('.pkl', '').replace('.pth', '')
            
            if symbol not in model_summary:
                model_summary[symbol] = {}
            
            model_summary[symbol][model_type] = {
                'file': file,
                'timestamp': timestamp,
                'size_mb': os.path.getsize(os.path.join(models_dir, file)) / (1024*1024),
                'path': os.path.join(models_dir, file)
            }
    
    return model_summary

def analyze_model_complexity(model_path, model_type):
    """Analyze the complexity and learning capacity of a model"""
    try:
        if model_path.endswith('.pth'):
            # LSTM model
            model = torch.load(model_path, map_location='cpu')
            if hasattr(model, 'state_dict'):
                total_params = sum(p.numel() for p in model.parameters())
                trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
                return {
                    'type': 'LSTM',
                    'total_parameters': total_params,
                    'trainable_parameters': trainable_params,
                    'model_size_mb': os.path.getsize(model_path) / (1024*1024)
                }
        else:
            # Sklearn models (Random Forest, XGBoost, LightGBM)
            model = joblib.load(model_path)
            
            if hasattr(model, 'n_estimators'):
                # Random Forest / XGBoost / LightGBM
                n_estimators = getattr(model, 'n_estimators', 'Unknown')
                max_depth = getattr(model, 'max_depth', 'Unknown')
                
                if hasattr(model, 'feature_importances_'):
                    importance = model.feature_importances_
                    top_features = len(importance[importance > np.mean(importance)])
                else:
                    top_features = 'Unknown'
                
                return {
                    'type': model_type.upper(),
                    'n_estimators': n_estimators,
                    'max_depth': max_depth,
                    'top_features': top_features,
                    'model_size_mb': os.path.getsize(model_path) / (1024*1024)
                }
    except Exception as e:
        return {'error': str(e)}

def generate_learning_report():
    """Generate comprehensive learning analysis report"""
    print("üìä **Model Learning Analysis Report**")
    print("=" * 50)
    
    model_summary = analyze_model_files()
    
    if not model_summary:
        print("No models to analyze")
        return
    
    # Overall statistics
    total_symbols = len(model_summary)
    total_models = sum(len(models) for models in model_summary.values())
    
    print(f"üìà **Training Coverage:**")
    print(f"   ‚Ä¢ Symbols Trained: {total_symbols}")
    print(f"   ‚Ä¢ Total Models: {total_models}")
    print(f"   ‚Ä¢ Model Types: LSTM, Random Forest, XGBoost, LightGBM")
    
    # Symbol breakdown
    print(f"\nüéØ **Symbols Trained:**")
    for symbol, models in sorted(model_summary.items()):
        model_types = ', '.join(models.keys())
        count = len(models)
        print(f"   ‚Ä¢ {symbol}: {count} models ({model_types})")
    
    # Model complexity analysis
    print(f"\nüîç **Model Complexity Analysis:**")
    
    models_dir = "c:\\Users\\hp\\Binancebot\\models"
    complexity_summary = {}
    
    for symbol, models in model_summary.items():
        for model_type, info in models.items():
            complexity = analyze_model_complexity(info['path'], model_type)
            if 'error' not in complexity:
                if model_type not in complexity_summary:
                    complexity_summary[model_type] = []
                complexity_summary[model_type].append(complexity)
    
    # Average complexity by model type
    for model_type, models in complexity_summary.items():
        if model_type == 'lstm':
            avg_params = np.mean([m['total_parameters'] for m in models])
            avg_size = np.mean([m['model_size_mb'] for m in models])
            print(f"   ‚Ä¢ **LSTM**: ~{avg_params:,.0f} parameters, {avg_size:.1f}MB average")
        else:
            avg_estimators = np.mean([m['n_estimators'] for m in models if str(m['n_estimators']).isdigit()])
            avg_depth = np.mean([m['max_depth'] for m in models if str(m['max_depth']).isdigit()])
            avg_size = np.mean([m['model_size_mb'] for m in models])
            print(f"   ‚Ä¢ **{model_type.upper()}**: ~{avg_estimators:.0f} trees, depth ~{avg_depth}, {avg_size:.1f}MB average")
    
    # Training frequency analysis
    print(f"\nüîÑ **Training Frequency:**")
    timestamps = []
    for symbol, models in model_summary.items():
        for model_type, info in models.items():
            try:
                ts = datetime.strptime(info['timestamp'], '%Y%m%d_%H%M%S')
                timestamps.append(ts)
            except:
                pass
    
    if timestamps:
        first_train = min(timestamps)
        last_train = max(timestamps)
        total_sessions = len(set(timestamps))
        print(f"   ‚Ä¢ **Training Period**: {first_train.strftime('%Y-%m-%d %H:%M')} to {last_train.strftime('%Y-%m-%d %H:%M')}")
        print(f"   ‚Ä¢ **Retraining Sessions**: {total_sessions}")
        print(f"   ‚Ä¢ **Models per Session**: {total_models / total_sessions:.1f}")
    
    print(f"\nüí° **Learning Insights:**")
    print(f"   ‚Ä¢ **Ensemble Strategy**: Each symbol has 4 model types for robust predictions")
    print(f"   ‚Ä¢ **Model Diversity**: Combines deep learning (LSTM) with tree-based methods")
    print(f"   ‚Ä¢ **Continuous Learning**: Models retrained regularly with fresh data")
    print(f"   ‚Ä¢ **Feature Engineering**: Models learn from 50+ technical indicators")
    print(f"   ‚Ä¢ **Market Adaptation**: Training includes market regime detection")

if __name__ == "__main__":
    generate_learning_report()